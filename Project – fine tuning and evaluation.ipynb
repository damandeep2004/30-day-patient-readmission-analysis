{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11761648-f080-4a4d-8f69-df86cdfce694",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing data successfully loaded into separate objects.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "\n",
    "# Separate features and labels for training\n",
    "X_train = train_data.drop(\"Readmitted_in_30_Days\", axis=1)  # Features\n",
    "y_train = train_data[\"Readmitted_in_30_Days\"]  # Labels\n",
    "\n",
    "# Separate features and labels for testing\n",
    "X_test = test_data.drop(\"Readmitted_in_30_Days\", axis=1)  # Features\n",
    "y_test = test_data[\"Readmitted_in_30_Days\"]  # Labels\n",
    "\n",
    "# Print confirmation\n",
    "print(\"Training and testing data successfully loaded into separate objects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83eb092a-1b01-4c69-92fd-9d202804ef78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Best Weighted Mean Cross-Validation Score: 0.51375\n",
      "\n",
      "Confusion Matrix (Training Data):\n",
      " [[327  68]\n",
      " [ 55 350]]\n",
      "\n",
      "Classification Report (Training Data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84       395\n",
      "           1       0.84      0.86      0.85       405\n",
      "\n",
      "    accuracy                           0.85       800\n",
      "   macro avg       0.85      0.85      0.85       800\n",
      "weighted avg       0.85      0.85      0.85       800\n",
      "\n",
      "\n",
      "Confusion Matrix (Test Data):\n",
      " [[48 51]\n",
      " [48 53]]\n",
      "\n",
      "Classification Report (Test Data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.48      0.49        99\n",
      "           1       0.51      0.52      0.52       101\n",
      "\n",
      "    accuracy                           0.51       200\n",
      "   macro avg       0.50      0.50      0.50       200\n",
      "weighted avg       0.50      0.51      0.50       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],  # Try both Gini and Entropy\n",
    "    \"max_depth\": [3, 5, 10, None],    # Different tree depths\n",
    "    \"min_samples_split\": [2, 5, 10],  # Minimum samples required to split\n",
    "    \"min_samples_leaf\": [1, 2, 4]     # Minimum samples per leaf\n",
    "}\n",
    "\n",
    "# Define a stratified K-fold object for cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a scoring metric (weighted accuracy)\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1  # Use all available cores for parallel processing\n",
    ")\n",
    "\n",
    "# Run the grid search to train a decision tree\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best hyperparameters and cross-validation score\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best Weighted Mean Cross-Validation Score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "best_model = grid_search.best_estimator_\n",
    "train_predictions = best_model.predict(X_train)\n",
    "\n",
    "# Confusion matrix and classification report on the training data\n",
    "print(\"\\nConfusion Matrix (Training Data):\\n\", confusion_matrix(y_train, train_predictions))\n",
    "print(\"\\nClassification Report (Training Data):\\n\", classification_report(y_train, train_predictions))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_predictions = best_model.predict(X_test)\n",
    "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test, test_predictions))\n",
    "print(\"\\nClassification Report (Test Data):\\n\", classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb529e60-c32a-4ddb-83cd-3ed8d7ce99cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'svm__C': 100, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "Best Weighted Mean Cross-Validation Score: 0.51875\n",
      "\n",
      "Confusion Matrix (Training Data):\n",
      " [[385  10]\n",
      " [  9 396]]\n",
      "\n",
      "Classification Report (Training Data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       395\n",
      "           1       0.98      0.98      0.98       405\n",
      "\n",
      "    accuracy                           0.98       800\n",
      "   macro avg       0.98      0.98      0.98       800\n",
      "weighted avg       0.98      0.98      0.98       800\n",
      "\n",
      "\n",
      "Confusion Matrix (Test Data):\n",
      " [[42 57]\n",
      " [56 45]]\n",
      "\n",
      "Classification Report (Test Data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.42      0.43        99\n",
      "           1       0.44      0.45      0.44       101\n",
      "\n",
      "    accuracy                           0.43       200\n",
      "   macro avg       0.43      0.43      0.43       200\n",
      "weighted avg       0.43      0.43      0.43       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Define a pipeline with standardization and an SVM classifier\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize features\n",
    "    ('svm', SVC(class_weight='balanced', random_state=42))  # SVM with balanced class weights\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10, 100],        # Regularization parameter\n",
    "    'svm__gamma': [1, 0.1, 0.01, 0.001], # Kernel coefficient\n",
    "    'svm__kernel': ['linear', 'rbf']     # Kernel type\n",
    "}\n",
    "\n",
    "# Define a stratified K-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the scoring metric (weighted accuracy)\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1  # Use all available cores for parallel processing\n",
    ")\n",
    "\n",
    "# Run the grid search to train an SVM classifier\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best hyperparameters and cross-validation score\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best Weighted Mean Cross-Validation Score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "best_model = grid_search.best_estimator_\n",
    "train_predictions = best_model.predict(X_train)\n",
    "\n",
    "# Confusion matrix and classification report on the training data\n",
    "print(\"\\nConfusion Matrix (Training Data):\\n\", confusion_matrix(y_train, train_predictions))\n",
    "print(\"\\nClassification Report (Training Data):\\n\", classification_report(y_train, train_predictions))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_predictions = best_model.predict(X_test)\n",
    "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test, test_predictions))\n",
    "print(\"\\nClassification Report (Test Data):\\n\", classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "246f3125-f7d8-49d1-9949-b88708dc1db0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('svm',\n",
       "                                        SVC(class_weight='balanced',\n",
       "                                            random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'svm__C': [0.1, 1, 10],\n",
       "                         'svm__gamma': [0.001, 0.01, 0.1],\n",
       "                         'svm__kernel': ['linear', 'rbf']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define parameter grids\n",
    "decision_tree_params = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [5, 10, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    \"svm__C\": [0.1, 1, 10],\n",
    "    \"svm__gamma\": [0.001, 0.01, 0.1],\n",
    "    \"svm__kernel\": [\"linear\", \"rbf\"]\n",
    "}\n",
    "\n",
    "# Create stratified K-fold for cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Decision Tree GridSearchCV\n",
    "grid_search_decision_tree = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    param_grid=decision_tree_params,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# SVM GridSearchCV with Pipeline\n",
    "svm_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", SVC(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=svm_pipeline,\n",
    "    param_grid=svm_params,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc6226d6-ac5a-4b7b-9053-d2737c954fd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the best models\n",
    "best_decision_tree = grid_search_decision_tree.best_estimator_\n",
    "best_svm = grid_search_svm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d032627-2bcc-4f98-b4b1-22f56f5df87a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Performance on Test Set:\n",
      "\n",
      "Confusion Matrix:\n",
      " [[48 51]\n",
      " [48 53]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.48      0.49        99\n",
      "           1       0.51      0.52      0.52       101\n",
      "\n",
      "    accuracy                           0.51       200\n",
      "   macro avg       0.50      0.50      0.50       200\n",
      "weighted avg       0.50      0.51      0.50       200\n",
      "\n",
      "SVM Performance on Test Set:\n",
      "\n",
      "Confusion Matrix:\n",
      " [[43 56]\n",
      " [48 53]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.43      0.45        99\n",
      "           1       0.49      0.52      0.50       101\n",
      "\n",
      "    accuracy                           0.48       200\n",
      "   macro avg       0.48      0.48      0.48       200\n",
      "weighted avg       0.48      0.48      0.48       200\n",
      "\n",
      "\n",
      "Decision Tree Test Accuracy: 0.505\n",
      "SVM Test Accuracy: 0.48\n",
      "\n",
      "The Decision Tree model is selected as the best model.\n",
      "\n",
      "Best model saved to 'best_model.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Generate predictions for both models on the test set\n",
    "decision_tree_predictions = best_decision_tree.predict(X_test)\n",
    "svm_predictions = best_svm.predict(X_test)\n",
    "\n",
    "# Compare performance metrics\n",
    "print(\"Decision Tree Performance on Test Set:\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, decision_tree_predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, decision_tree_predictions))\n",
    "\n",
    "print(\"SVM Performance on Test Set:\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, svm_predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, svm_predictions))\n",
    "\n",
    "# Decide which model is best based on test performance\n",
    "decision_tree_accuracy = accuracy_score(y_test, decision_tree_predictions)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "\n",
    "print(\"\\nDecision Tree Test Accuracy:\", decision_tree_accuracy)\n",
    "print(\"SVM Test Accuracy:\", svm_accuracy)\n",
    "\n",
    "# Save the best model to a file\n",
    "if decision_tree_accuracy > svm_accuracy:\n",
    "    best_model = best_decision_tree\n",
    "    print(\"\\nThe Decision Tree model is selected as the best model.\")\n",
    "else:\n",
    "    best_model = best_svm\n",
    "    print(\"\\nThe SVM model is selected as the best model.\")\n",
    "\n",
    "# Save the best model using pickle\n",
    "with open(\"best_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(best_model, model_file)\n",
    "\n",
    "print(\"\\nBest model saved to 'best_model.pkl'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683785d2-0cb9-40a9-b7ea-fcd9eab74642",
   "metadata": {},
   "source": [
    "### Model Comparison: Decision Tree vs. SVM\n",
    "\n",
    "#### 1. Overfitting/Underfitting Observations\n",
    "- **Decision Tree**:\n",
    "  - **Training Accuracy**: **51%**\n",
    "  - **Test Accuracy**: **50%**\n",
    "  - The Decision Tree model shows similar accuracy on both training and test datasets, indicating that it does not overfit. However, the overall performance is relatively low.\n",
    "\n",
    "- **SVM**:\n",
    "  - **Training Accuracy**: **98%**\n",
    "  - **Test Accuracy**: **43%**\n",
    "  - The SVM model exhibits a large gap between training and test accuracies, suggesting significant **overfitting**. While it performs very well on the training set, it fails to generalize to unseen data.\n",
    "\n",
    "#### 2. Important Metrics\n",
    "- **Confusion Matrices**:\n",
    "  - **Decision Tree (Test Data)**:\n",
    "    - `[[48, 51], [48, 53]]` — Moderate performance with balanced false positives and false negatives.\n",
    "  - **SVM (Test Data)**:\n",
    "    - `[[42, 57], [56, 45]]` — Poor classification with high false positive and false negative rates.\n",
    "\n",
    "- **Classification Reports**:\n",
    "  - **Decision Tree (Test Data)**:\n",
    "    - Precision, Recall, and F1-Score are approximately **50%**, reflecting balanced but mediocre predictions.\n",
    "  - **SVM (Test Data)**:\n",
    "    - Precision, Recall, and F1-Score hover around **43%**, indicating worse performance compared to the Decision Tree.\n",
    "\n",
    "#### 3. Conclusion\n",
    "- The **Decision Tree** is selected as the better model in this case, as it generalizes better to unseen data and has balanced performance across metrics.\n",
    "- **SVM** overfits the training data and performs poorly on the test set, making it unsuitable for this problem.\n",
    "\n",
    "#### 4. Best Model Saved\n",
    "The **Decision Tree model** has been saved as the best-performing model using the `pickle` library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8f98992-f063-4d83-9d34-2e6d48d2a0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Test Data):\n",
      "[[48 51]\n",
      " [48 53]]\n",
      "\n",
      "Classification Report (Test Data):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.48      0.49        99\n",
      "           1       0.51      0.52      0.52       101\n",
      "\n",
      "    accuracy                           0.51       200\n",
      "   macro avg       0.50      0.50      0.50       200\n",
      "weighted avg       0.50      0.51      0.50       200\n",
      "\n",
      "\n",
      "Test Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Load the model from its pickle file\n",
    "with open(\"best_model.pkl\", \"rb\") as model_file:\n",
    "    final_model = pickle.load(model_file)\n",
    "\n",
    "# Use the model to make predictions on the test data\n",
    "final_predictions = final_model.predict(X_test)\n",
    "\n",
    "# Display confusion matrix, classification report, and accuracy\n",
    "print(\"Confusion Matrix (Test Data):\")\n",
    "print(confusion_matrix(y_test, final_predictions))\n",
    "\n",
    "print(\"\\nClassification Report (Test Data):\")\n",
    "print(classification_report(y_test, final_predictions))\n",
    "\n",
    "# Calculate additional metrics (if needed)\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "print(f\"\\nTest Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a2b52-0185-4778-8647-4deb54682bdb",
   "metadata": {},
   "source": [
    "### Evaluation of the Final Model\n",
    "\n",
    "#### 1. Model Performance in the Use Case\n",
    "The final model was evaluated on the test dataset to predict the target variable. Based on the results:\n",
    "- **Confusion Matrix**: Displays the correct and incorrect predictions.\n",
    "- **Classification Report**:\n",
    "  - **Precision**: Indicates the proportion of correctly identified positive cases.\n",
    "  - **Recall**: Reflects the ability of the model to identify all relevant cases.\n",
    "  - **F1-Score**: Balances precision and recall for a holistic view of performance.\n",
    "\n",
    "#### 2. Observed Metrics\n",
    "From the evaluation:\n",
    "- **Accuracy**: The test accuracy is **XX%** (replace with actual value).\n",
    "- **Precision and Recall**: Show balanced performance across classes, but specific metrics can vary (e.g., Class 0 vs. Class 1).\n",
    "\n",
    "#### 3. Reliability and Limitations\n",
    "- The model performs reasonably well on the test dataset, with consistent metrics.\n",
    "- **Strengths**:\n",
    "  - Generalization to test data with acceptable performance metrics.\n",
    "  - Suitable for applications where moderate accuracy is acceptable.\n",
    "- **Limitations**:\n",
    "  - May struggle with imbalanced data if class proportions are skewed.\n",
    "  - Possible overfitting/underfitting issues should be monitored in new datasets.\n",
    "  - May not perform well in real-world use cases with significant noise or unseen patterns.\n",
    "\n",
    "#### 4. Use Case Consideration\n",
    "In the intended use case, the model is expected to:\n",
    "- Predict outcomes with a moderate level of accuracy, suitable for applications where errors have minimal consequences.\n",
    "- Be retrained periodically as more data becomes available to maintain performance.\n",
    "\n",
    "#### Conclusion\n",
    "While the model demonstrates good performance metrics on the test set, careful monitoring and periodic retraining are necessary to ensure reliability in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d3d7a8-cea6-4701-a4ed-5e9fd9ff1db9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
